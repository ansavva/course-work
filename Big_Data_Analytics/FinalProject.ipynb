{"cells":[{"cell_type":"code","source":["from bs4 import BeautifulSoup\nimport urllib\n\nrawDataFile = open('tarrant_county_raw.csv', 'r')\n\nstart = True\nrawDataLines = []\nfor line in rawDataFile.readlines():\n    if (not start):\n        line = line.replace('\\n', '')\n        line = line.replace('\\xff', '')\n        line = line.strip()\n        variables = line.split(',')\n        if (len(variables) == 7):\n            variables[5] = variables[5] + variables[6]\n            variables[5] = variables[5].replace('$', '')\n        variables.pop()\n        rawDataLines.append(variables)\n    start = False\n    \nrawDataFile.close()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":1},{"cell_type":"code","source":["import time\nfrom datetime import datetime\n\nfileName = \"tarrant_county_\" + datetime.now().strftime(\"%m_%d_%Y_%M_%S\") + \".txt\"\n\nparsedDataFile = open(fileName, 'w')\n\nparsedDataFile.write('id;address;land_market_share;impr_market_share;total_market_share;land_appraisal_value;impr_appraisal_value;total_appraisal_value;land_approximate_size;impr_approximate_size;total_approximate_size;land_land_acres;impr_land_acres;total_land_acres;land_land_sqft;impr_land_sqft;total_land_sqft' + '\\n')\n\nfor rawDataLine in rawDataLines:\n    try:\n        # Get the html and parse it using beautiful soup\n        r = urllib.urlopen('http://www.tad.org/property-data-sheet-residential?keyword=' + rawDataLine[0]).read()\n        soup = BeautifulSoup(r, 'html.parser')\n\n        line = ''\n        \n        line = rawDataLine[0] + \";\"\n        \n        # Isolate the home's address\n        tables = soup.findAll(\"table\")\n        tableRows = tables[0].findAll(\"tr\")\n        tableCells = tableRows[2].findAll(\"td\")\n        line = line + tableCells[1].text.strip() + ';'\n\n        dataRows = tables[1].findAll('tr')\n        cells = []\n        for row in dataRows:\n            dataCells = row.findAll('td')\n            for dataCell in dataCells:\n                cells.append(dataCell.text.strip())\n\n        indexes = [5,6,7,9,10,11,13,14,15,17,18,19,21,22,23]\n\n        for index in indexes:\n            if (cells[index] != ''):\n                line = line + cells[index].replace('$', '').replace(',', '').strip() + ';'\n            else:\n                line = line + 'NULL' + ';'\n        line = line[:-1]\n        parsedDataFile.write(line + '\\n')\n    except:\n        print(\"Error with record: \" + rawDataLine[0])\n        continue\n    time.sleep(2)\n    \nparsedDataFile.close()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":2},{"cell_type":"code","source":["headers = open(\"tarrant_county_04_27_2017_04_58.txt\", 'r').readlines()[0]\nindex = 1\nwhile (index < 5):\n    with open(\"tarrant_county_04_27_2017_04_58_\" + str(index) + \".txt\", 'a') as outfile:\n        outfile.write(headers)\n    index = index + 1\nindex = 1\nfor row in open(\"tarrant_county_04_27_2017_04_58.txt\", 'r').readlines():\n    with open(\"tarrant_county_04_27_2017_04_58_\" + str(index) + \".txt\", 'a') as outfile:\n        outfile.write(row)\n    if (index == 4):\n        index = 0\n    index = index + 1"],"metadata":{"collapsed":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":["import time\nimport zillow\nimport pprint\nimport json\nimport os.path\nfrom datetime import datetime\n\npp = pprint.PrettyPrinter(indent=4)\nfirstLoop = True\nheaders = []\n\nif not os.path.exists('zillow_address_found.txt'):\n    open('zillow_address_found.txt', 'w').close()\n\ndef convertRowToDict(headers, dataParts):\n    index = 0\n    dataDict = {}\n    for header in headers:\n        header = header.replace('\\n', '').strip()\n        dataDict[header] = dataParts[index].replace('\\n', '').strip()\n        index = index + 1\n    return dataDict\n\nfileName = \"full_data_set_\" + datetime.now().strftime(\"%m_%d_%Y_%M_%S\") + \".txt\"\n\nwith open(fileName, 'a') as outfile:\n    for row in open(\"tarrant_county_04_27_2017_04_58_4.txt\", 'r').readlines():\n        detailDataDict = {}\n        dataParts = row.split(';')\n        if firstLoop:\n            headers = dataParts\n            firstLoop = False\n        else:\n            try:\n                found = False\n                with open('zillow_address_found.txt', 'r') as zillowDataFound:\n                    for line in zillowDataFound.readlines():\n                        if(dataParts[1].upper() in line.upper()):\n                            found = True\n                            break\n                if not found:\n                    addressParts = dataParts[1].split(',')\n                    address = addressParts[0].strip() + ', ' + addressParts[1].strip()\n                    postalCode = addressParts[2].strip()\n                    #key = \"X1-ZWz198ccdzns3v_6frtk\" # old\n                    #key = \"X1-ZWz1fsdkwnam17_1pt0f\" # new\n                    key = \"X1-ZWz1fse0ow71u3_211k7\" # new new\n                    api = zillow.ValuationApi()\n                    detailDataDict[\"zillow\"] = api.GetDeepSearchResults(key, address, postalCode).get_dict()\n                    detailDataDict[\"success\"] = True\n                    with open('zillow_address_found.txt', 'a') as zillowDataFound:\n                        zillowDataFound.write(dataParts[1] + '\\n')\n                else:\n                    detailDataDict[\"success\"] = False\n            except:\n                detailDataDict[\"success\"] = False\n            if detailDataDict[\"success\"]:\n                detailDataDict[\"tarrant_county_data\"] = convertRowToDict(headers, dataParts)\n                json.dump(detailDataDict, outfile)\n                outfile.write('\\n')\n                print(str(detailDataDict[\"tarrant_county_data\"][\"address\"]) + \", \" + str(detailDataDict[\"success\"]))"],"metadata":{"collapsed":false,"scrolled":false},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from os import listdir\n\nwith open(\"final_data_set.txt\", 'w') as outfile:\n    for directory in listdir(\"C:/Users/asavv/Google Drive/Andreas Documents/Education/Course Work/INSY 5376 - Big Data Analytics\\Project\"):\n        if \"full_data_set_\" in directory:\n            print(directory)\n            for line in open(directory, 'r').readlines():\n                outfile.write(line)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":5},{"cell_type":"code","source":["import pprint\nimport json\n    \ndef variableCheck(jsonRecord):\n    if jsonRecord is not None:\n        return str(jsonRecord).strip()\n    else:\n        return \"NULL\"\n    \nidAdded = []\n\nwith open('final_data_set.csv', 'w') as csvfile:\n    csvfile.write('id,zpid,address,city,zipcode,total_approximate_size,total_appraisal_value,' +\n                  'total_market_share,zestimate_amount,valuation_range_high,valuation_range_low,' + \n                  'bedrooms,bathrooms,usecode,last_sold_date,year_built,complete,finished_sqft\\n')\n    with open('final_data_set.txt', 'r') as outfile:\n        jsonDocs = outfile.readlines()\n        for jsonDoc in jsonDocs:\n            jsonRecord = json.loads(jsonDoc)\n            if jsonRecord[\"tarrant_county_data\"][\"id\"] not in idAdded:\n                variables = []\n                variables.append(variableCheck(jsonRecord[\"tarrant_county_data\"][\"id\"]))\n                variables.append(variableCheck(jsonRecord[\"zillow\"][\"zpid\"]))\n                \n                for address_line in jsonRecord[\"tarrant_county_data\"][\"address\"].split(','):\n                    variables.append(variableCheck(address_line))\n                \n                variables.append(variableCheck(jsonRecord[\"tarrant_county_data\"][\"total_approximate_size\"]))\n                variables.append(variableCheck(jsonRecord[\"tarrant_county_data\"][\"total_appraisal_value\"]))\n                variables.append(variableCheck(jsonRecord[\"tarrant_county_data\"][\"total_market_share\"]))\n                \n                variables.append(variableCheck(jsonRecord[\"zillow\"][\"zestimate\"][\"amount\"]))\n                variables.append(variableCheck(jsonRecord[\"zillow\"][\"zestimate\"][\"valuation_range_high\"]))\n                variables.append(variableCheck(jsonRecord[\"zillow\"][\"zestimate\"][\"valuation_range_low\"]))\n                \n                variables.append(variableCheck(jsonRecord[\"zillow\"][\"extended_data\"][\"bedrooms\"]))\n                variables.append(variableCheck(jsonRecord[\"zillow\"][\"extended_data\"][\"bathrooms\"]))\n                \n                variables.append(variableCheck(jsonRecord[\"zillow\"][\"extended_data\"][\"usecode\"]))\n                variables.append(variableCheck(jsonRecord[\"zillow\"][\"extended_data\"][\"last_sold_date\"]))\n                variables.append(variableCheck(jsonRecord[\"zillow\"][\"extended_data\"][\"year_built\"]))\n                variables.append(variableCheck(jsonRecord[\"zillow\"][\"extended_data\"][\"complete\"]))\n                variables.append(variableCheck(jsonRecord[\"zillow\"][\"extended_data\"][\"finished_sqft\"]))\n                \n                line = ''\n                for variable in variables:\n                    line = line + variable + ','\n                line = line.strip(',')\n                csvfile.write(line + '\\n')\n                idAdded.append(jsonRecord[\"tarrant_county_data\"][\"id\"])\nprint(\"Done\")"],"metadata":{"collapsed":false},"outputs":[],"execution_count":6},{"cell_type":"code","source":[""],"metadata":{"collapsed":false},"outputs":[],"execution_count":7}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.13","nbconvert_exporter":"python","file_extension":".py"},"name":"FinalProject","notebookId":1424210199374828},"nbformat":4,"nbformat_minor":0}
